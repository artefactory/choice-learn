{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAM usage with Choice-Learn\n",
    "\n",
    "## On the ICDM 2013 Expedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pf\n",
    "\n",
    "from choice_learn.datasets import load_expedia\n",
    "from choice_learn.data import ChoiceDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the RAM usag is actually not that obvious. Here is a code snippet finding all references link to an object in order to addition their memory consumption.\n",
    "This is explained [here](https://stackoverflow.com/questions/13530762/how-to-know-bytes-size-of-python-object-like-arrays-and-dictionaries-the-simp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "\n",
    "def get_obj_size(obj):\n",
    "    marked = {id(obj)}\n",
    "    obj_q = [obj]\n",
    "    sz = 0\n",
    "\n",
    "    while obj_q:\n",
    "        sz += sum(map(sys.getsizeof, obj_q))\n",
    "\n",
    "        # Lookup all the object referred to by the object in obj_q.\n",
    "        all_refr = ((id(o), o) for o in gc.get_referents(*obj_q))\n",
    "\n",
    "        # Filter object that are already marked.\n",
    "        new_refr = {o_id: o for o_id, o in all_refr if o_id not in marked and not isinstance(o, type)}\n",
    "\n",
    "        obj_q = new_refr.values()\n",
    "        marked.update(new_refr.keys())\n",
    "\n",
    "    return sz\n",
    "\n",
    "# Defining tested data lengths\n",
    "data_lengths = [100, 1000, 10000, 100000, 397618]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Choice-Learn and FeaturesByIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes some time\n",
    "dataset = load_expedia(as_frame=False, preprocessing=\"rumnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_w_fbid_memory_size = []\n",
    "for length in data_lengths:\n",
    "    sub_dataset = dataset[:length]\n",
    "    mem_size = 0\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.shared_features_by_choice))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.items_features_by_choice))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.choices))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.available_items_by_choice))\n",
    "    mem_size += get_obj_size(sub_dataset.features_by_ids)\n",
    "    cl_w_fbid_memory_size.append(mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl_w_fbid_memory_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice-Learn without FeaturesByIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_expedia(as_frame=False, preprocessing=\"rumnet\")\n",
    "sfbc = []\n",
    "ifbc = []\n",
    "for batch in dataset.iter_batch(batch_size=1024):\n",
    "    batch_sfbc = batch[0]\n",
    "    sfbc.append(batch[0])\n",
    "    ifbc.append(batch[1])\n",
    "\n",
    "sfbc = np.concatenate(sfbc, axis=0)\n",
    "ifbc = np.concatenate(ifbc, axis=0)\n",
    "print(sfbc.shape, ifbc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_fbid_dataset = ChoiceDataset(\n",
    "    shared_features_by_choice=sfbc,\n",
    "    items_features_by_choice=ifbc,\n",
    "    available_items_by_choice=dataset.available_items_by_choice,\n",
    "    choices=dataset.choices\n",
    ")\n",
    "\n",
    "wofbid_mem = []\n",
    "for length in data_lengths:\n",
    "    sub_dataset = wo_fbid_dataset[:length]\n",
    "    mem_size = 0\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.shared_features_by_choice))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.items_features_by_choice))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.choices))\n",
    "    mem_size += get_obj_size(np.copy(sub_dataset.available_items_by_choice))\n",
    "    mem_size += get_obj_size(sub_dataset.features_by_ids)\n",
    "    wofbid_mem.append(mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wofbid_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_w_fbid_memory_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wofbid_mem, label=\"without\")\n",
    "plt.plot(cl_w_fbid_memory_size, label=\"with\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_fbid_dataset.available_items_by_choice[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_obj_size(np.copy(dataset.shared_features_by_choice[0])) / get_obj_size(np.copy(wo_fbid_dataset.shared_features_by_choice[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.DataFrame Long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "expedia_df = load_expedia(as_frame=True)\n",
    "logging.info(\"rumnet preprocessing selected, starting preprocessing...\")\n",
    "expedia_df.date_time = pd.to_datetime(expedia_df.date_time, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "expedia_df.loc[:, \"day_of_week\"] = expedia_df.loc[:, \"date_time\"].dt.dayofweek\n",
    "expedia_df.loc[:, \"month\"] = expedia_df.loc[:, \"date_time\"].dt.month\n",
    "expedia_df.loc[:, \"hour\"] = expedia_df.loc[:, \"date_time\"].dt.hour\n",
    "\n",
    "logging.info(\"Filtering ids with less than 1000 occurrences\")\n",
    "for id_col in [\n",
    "    \"site_id\",\n",
    "    \"visitor_location_country_id\",\n",
    "    \"prop_country_id\",\n",
    "    \"srch_destination_id\",\n",
    "]:\n",
    "    value_counts = expedia_df[[\"srch_id\", id_col]].drop_duplicates()[id_col].value_counts()\n",
    "    kept_ids = value_counts.index[value_counts.gt(1000)]\n",
    "    for id_ in expedia_df[id_col].unique():\n",
    "        if id_ not in kept_ids:\n",
    "            expedia_df.loc[expedia_df[id_col] == id_, id_col] = -1\n",
    "\n",
    "logging.info(\"Filtering DF for price, stay length, booking window, etc.\")\n",
    "# Filtering\n",
    "expedia_df = expedia_df[expedia_df.price_usd <= 1000]\n",
    "expedia_df = expedia_df[expedia_df.price_usd >= 10]\n",
    "expedia_df[\"log_price\"] = expedia_df.price_usd.apply(np.log)\n",
    "expedia_df = expedia_df[expedia_df.srch_length_of_stay <= 14]\n",
    "expedia_df = expedia_df[expedia_df.srch_booking_window <= 365]\n",
    "expedia_df[\"booking_window\"] = np.log(expedia_df[\"srch_booking_window\"] + 1)\n",
    "expedia_df = expedia_df.fillna(-1)\n",
    "\n",
    "logging.info(\"Sorting DF columns\")\n",
    "order_cols = [\n",
    "    \"srch_id\",\n",
    "    \"prop_id\",\n",
    "    \"prop_starrating\",\n",
    "    \"prop_review_score\",\n",
    "    \"prop_brand_bool\",\n",
    "    \"prop_location_score1\",\n",
    "    \"prop_location_score2\",\n",
    "    \"prop_log_historical_price\",\n",
    "    \"position\",\n",
    "    \"promotion_flag\",\n",
    "    \"srch_length_of_stay\",\n",
    "    \"srch_adults_count\",\n",
    "    \"srch_children_count\",\n",
    "    \"srch_room_count\",\n",
    "    \"srch_saturday_night_bool\",\n",
    "    \"orig_destination_distance\",\n",
    "    \"random_bool\",\n",
    "    \"day_of_week\",\n",
    "    \"month\",\n",
    "    \"hour\",\n",
    "    \"log_price\",\n",
    "    \"booking_window\",\n",
    "    \"site_id\",\n",
    "    \"visitor_location_country_id\",\n",
    "    \"prop_country_id\",\n",
    "    \"srch_destination_id\",\n",
    "    \"click_bool\",\n",
    "    \"booking_bool\",\n",
    "]\n",
    "expedia_df = expedia_df[order_cols]\n",
    "\n",
    "logging.info(\"Creating dummy availabilities\")\n",
    "\n",
    "# getting rid of search & prop_id and the clickbool and bookingbool\n",
    "# adding no_purchase fixed effect\n",
    "expedia_df[\"is_no_purchase\"] = 0\n",
    "\n",
    "logging.info(\"Creating the no purchase option\")\n",
    "# adding the no_purchase option to the data\n",
    "df1 = (\n",
    "    expedia_df.groupby(\"srch_id\")\n",
    "    .filter(lambda x: x.booking_bool.sum() == 1)\n",
    "    .groupby(\"srch_id\")\n",
    "    .max()\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df1.loc[:, \"is_no_purchase\"] = 1\n",
    "df1.loc[:, \"log_price\"] = 0\n",
    "df1.loc[:, \"booking_bool\"] = 0\n",
    "\n",
    "df2 = (\n",
    "    expedia_df.groupby(\"srch_id\")\n",
    "    .filter(lambda x: x.booking_bool.sum() == 0)\n",
    "    .groupby(\"srch_id\")\n",
    "    .max()\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df2.loc[:, \"is_no_purchase\"] = 1\n",
    "df2.loc[:, \"log_price\"] = 0\n",
    "df2.loc[:, \"booking_bool\"] = 1\n",
    "expedia_df = pd.concat([expedia_df, df1, df2])\n",
    "\n",
    "site_id_one_hot = pd.get_dummies(expedia_df.site_id, prefix=\"site_id\")\n",
    "visitor_location_country_id_one_hot = pd.get_dummies(expedia_df.visitor_location_country_id, prefix=\"visitor_location_country_id\")\n",
    "srch_destination_id_one_hot =pd.get_dummies(expedia_df.srch_destination_id, prefix=\"srch_destination_id\")\n",
    "prop_country_id_one_hpt = pd.get_dummies(expedia_df.prop_country_id, prefix=\"prop_country_id\")\n",
    "expedia_df = pd.concat([expedia_df, site_id_one_hot, visitor_location_country_id_one_hot, srch_destination_id_one_hot, prop_country_id_one_hpt], axis=1)\n",
    "\n",
    "logging.info(\"Sorting the data frame\")\n",
    "expedia_df = expedia_df.sort_values(\"srch_id\")\n",
    "choices = [\"booking_bool\"]\n",
    "\n",
    "logging.info(\"DF to NDarray and creating the ChoiceDataset object\")\n",
    "contexts_features_names = [\n",
    "    \"srch_id\",\n",
    "    \"srch_length_of_stay\",\n",
    "    \"srch_adults_count\",\n",
    "    \"srch_children_count\",\n",
    "    \"srch_room_count\",\n",
    "    \"srch_saturday_night_bool\",\n",
    "    \"booking_window\",\n",
    "    \"random_bool\",\n",
    "    \"day_of_week\",\n",
    "    \"month\",\n",
    "    \"hour\",\n",
    "    \"site_id\",\n",
    "    \"visitor_location_country_id\",\n",
    "    \"srch_destination_id\",\n",
    "]\n",
    "contexts_features_names += site_id_one_hot.columns.tolist()\n",
    "contexts_features_names += visitor_location_country_id_one_hot.columns.tolist()\n",
    "contexts_features_names += srch_destination_id_one_hot.columns.tolist()\n",
    "contexts_features_names += prop_country_id_one_hpt.columns.tolist()\n",
    "\n",
    "contexts_items_features_names = [\n",
    "    \"prop_starrating\",\n",
    "    \"prop_review_score\",\n",
    "    \"prop_brand_bool\",\n",
    "    \"prop_location_score1\",\n",
    "    \"prop_location_score2\",\n",
    "    \"prop_log_historical_price\",\n",
    "    \"position\",\n",
    "    \"promotion_flag\",\n",
    "    \"orig_destination_distance\",\n",
    "    \"log_price\",\n",
    "    \"prop_country_id\",\n",
    "]\n",
    "\n",
    "long_df = expedia_df[contexts_features_names + contexts_items_features_names + choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df_memory_size = []\n",
    "for length in data_lengths:\n",
    "    srch_ids = long_df.srch_id.unique()[:length]\n",
    "    sub_long_df = long_df[long_df.srch_id.isin(srch_ids)]\n",
    "    long_df_memory_size.append(get_obj_size(sub_long_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "| Dataset size | 100 | 1.000 | 10.000 | 100.000 | 397.618 |\n",
    "|---|---|---|---|---|---|\n",
    "| CD w. FeaturesByIDs | 398.887 | 3.869.287 | 38.573.287 | 385.613.287 | 1.533.228.295 |\n",
    "| CD wo FeaturesByIDs | 190.028 | 1.887.428 | 18.861.428 | 188.601.428 | 749.908.976 |\n",
    "\n",
    "data_lengths: [100, 1000, 10000, 100000, 397618]\\\n",
    "ChoiceDataset with FeaturesByIDs: [85640, 771440, 7629440, 76209440, 302994356]\\\n",
    "ChoiceDataset without FeaturesByIDs: [220400, 2198600, 21980600, 219800600, 873964964]\\\n",
    "DF Long Format: [5521360, 52463080, 524667470, 5234198450, 20815361140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
