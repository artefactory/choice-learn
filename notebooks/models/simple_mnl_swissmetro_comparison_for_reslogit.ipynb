{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MNL modelling on the SwissMetro dataset\n",
    "\n",
    "We use the Swissmetro dataset to compare the implementations of the simple MNL and the reslogit model [1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Remove/Add GPU use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from choice_learn.data import ChoiceDataset\n",
    "from choice_learn.models.reslogit import ResLogit\n",
    "from choice_learn.models.simple_mnl import SimpleMNL\n",
    "from choice_learn.datasets import load_swissmetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firs, we create a ChoiceDataset from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_swissmetro(as_frame=False) # Use a preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.summary()\n",
    "print(f\"\\n\\n{type(dataset)=}\")\n",
    "print(f\"\\n{np.shape(dataset.items_features_by_choice)=}\")\n",
    "print(f\"{np.shape(dataset.shared_features_by_choice)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just use a numpy based train/test split for cross-validation, but the core code is the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = np.shape(dataset.items_features_by_choice)[2]\n",
    "n_items_features = np.shape(dataset.items_features_by_choice)[3]\n",
    "n_shared_features = np.shape(dataset.shared_features_by_choice)[2]\n",
    "n_vars = n_items_features + n_shared_features\n",
    "n_choices = len(np.unique(dataset.choices))\n",
    "print(f\"{n_items=}\\n{n_items_features=}\\n{n_shared_features=}\\n{n_vars, n_choices=}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.permutation(list(range(len(dataset))))\n",
    "\n",
    "fit_losses = []\n",
    "test_eval = []\n",
    "for i in range(5):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    test_indexes = indexes[int(len(indexes) * 0.2 * i):int(len(indexes) * 0.2 * (i + 1))]\n",
    "    train_indexes = np.concatenate([indexes[:int(len(indexes) * 0.2 * i)],\n",
    "                                    indexes[int(len(indexes) * 0.2 * (i + 1)):]],\n",
    "                                    axis=0)\n",
    "    \n",
    "    # Ensure indexes are not empty\n",
    "    if len(train_indexes) == 0 or len(test_indexes) == 0:\n",
    "        print(f\"Skipping iteration {i} due to empty indexes.\")\n",
    "        continue\n",
    "\n",
    "    train_dataset = dataset[train_indexes]\n",
    "    test_dataset = dataset[test_indexes]\n",
    "\n",
    "    model = SimpleMNL()\n",
    "    model.instantiate(n_items=n_items, n_shared_features=n_shared_features, n_items_features=n_items_features)\n",
    "\n",
    "    losses = model.fit(choice_dataset=train_dataset)\n",
    "    probas = model.predict_probas(test_dataset)\n",
    "\n",
    "    eval = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_pred=probas, y_true=tf.one_hot(test_dataset.choices, n_items))\n",
    "    test_eval.append(eval)\n",
    "    print(test_eval)\n",
    "\n",
    "    fit_losses.append(losses)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    print(f\"Execution time for iteration {i}: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.coolwarm\n",
    "colors = [cmap(j / 4) for j in range(5)]\n",
    "for i in range(len(fit_losses)):\n",
    "    plt.plot(fit_losses[i][\"train_loss\"], label=f\"Training (fold {i})\", c=colors[i], linestyle=\"--\")\n",
    "    #plt.plot(fit_losses[i][\"test_loss\"], label=f\"Prediction (fold {i})\", c=colors[i])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Negative log likelihood\")\n",
    "plt.title(\"MNL model\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average LogLikeliHood on test:\", np.mean(test_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] ResLogit: A residual neural network logit model for data-driven choice modelling, Wong, M.; Farooq, B (2021), Transportation Research Part C: Emerging Technologies 126\\\n",
    "(URL: https://doi.org/10.1016/j.trc.2021.103050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
