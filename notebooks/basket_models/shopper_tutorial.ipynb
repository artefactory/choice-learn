{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to basket modelling with SHOPPER\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/artefactory/choice-learn/blob/main/notebooks/basket_models/shopper_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a synthetic dataset to demonstrate how to use the SHOPPER model [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary requirements\n",
    "\n",
    "# If you run this notebook on Google Colab, or in standalone mode, you need to install the required packages.\n",
    "# Uncomment the following lines:\n",
    "\n",
    "# !pip install choice-learn\n",
    "\n",
    "# If you run the notebook within the GitHub repository, you need to run the following lines, that can skipped otherwise:\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from choice_learn.basket_models import Trip, TripDataset\n",
    "from choice_learn.basket_models import Shopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all physical GPUs\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"Available physical GPUs: {physical_gpus}\")\n",
    "# Select GPUs to use\n",
    "selected_gpus = []  # Choose the GPUs you want to use ([] = CPU)\n",
    "# Set the selected GPUs to be visible\n",
    "tf.config.set_visible_devices(selected_gpus, \"GPU\")\n",
    "# Verify the visible GPUs\n",
    "visible_gpus = tf.config.get_visible_devices(\"GPU\")\n",
    "print(f\"Visible GPUs: {visible_gpus}\")\n",
    "\n",
    "# Limit GPU memory growth\n",
    "if physical_gpus:\n",
    "  try:\n",
    "    for gpu in physical_gpus:\n",
    "      # Allocate only as much GPU memory as needed for the runtime allocations\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple dataset where we have only six items sold in two different stores:\n",
    "- The first store sells items [0, 1, 2, 3, 4] and has observed baskets [1, 0], [2, 0], [1, 3, 4, 0];\n",
    "- The second store sells items [0, 1, 5, 6] and has observed baskets [1, 0], [6, 5, 0];\n",
    "\n",
    "with 0 the checkout item.\n",
    "\n",
    "Let's say that each basket has been seen 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = 7\n",
    "assortment_store_1 = np.array([1, 1, 1, 1, 1, 0, 0])\n",
    "assortment_store_2 = np.array([1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "available_items = np.array([assortment_store_1, assortment_store_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The list of available items are encoded as availability matrices indicating the availability (1) or not (0) of the products:\\n{available_items=}\\n\")\n",
    "print(\n",
    "    \"Here, the variable 'available_items' can be read as:\\n\",\n",
    "    f\"- Assortment 1 = {[i for i in range(n_items) if assortment_store_1[i]==1]}\\n\",\n",
    "    f\"- Assortment 2 = {[i for i in range(n_items) if assortment_store_2[i]==1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_baskets = 100\n",
    "\n",
    "purchases_stores_1 =[[1, 0], [2, 0], [1, 3, 4, 0]]\n",
    "purchases_stores_2 = [[1, 0], [6, 5, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our synthetic data, let's transform it as a TripDataset that will be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a list of Trip objects:\n",
    "trips_list = []\n",
    "\n",
    "for i in range(num_baskets):\n",
    "    trip = Trip(\n",
    "        purchases=purchases_stores_1[0],\n",
    "        # Let's consider here totally random prices for the products\n",
    "        prices=np.random.uniform(1, 10, n_items),\n",
    "        assortment=0\n",
    "    )\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(\n",
    "        purchases=purchases_stores_1[1],\n",
    "        prices=np.random.uniform(1, 10, n_items),\n",
    "        assortment=0\n",
    "    )\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(\n",
    "        purchases=purchases_stores_1[2],\n",
    "        prices=np.random.uniform(1, 10, n_items),\n",
    "        assortment=0\n",
    "    )\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(\n",
    "        purchases=purchases_stores_2[0],\n",
    "        prices=np.random.uniform(1, 10, n_items),\n",
    "        assortment=1\n",
    "    )\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(\n",
    "        purchases=purchases_stores_2[1],\n",
    "        prices=np.random.uniform(1, 10, n_items),\n",
    "        assortment=1\n",
    "    )\n",
    "    trips_list.append(trip)\n",
    "\n",
    "dataset = TripDataset(trips=trips_list, available_items=available_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SHOPPER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit a SHOPPER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Preferences and price effects are represented by latent variables of size 4 and 3, respectively.\n",
    "latent_sizes = {\"preferences\": 4, \"price\": 3}\n",
    "# We use 1 negative sample for each positive sample during the training phase.\n",
    "n_negative_samples = 1\n",
    "optimizer = \"adam\"\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: items fixed effect + items interactions + price effects\n",
    "shopper = Shopper(\n",
    "    item_intercept=False,\n",
    "    price_effects=True,\n",
    "    seasonal_effects=False,\n",
    "    latent_sizes=latent_sizes,\n",
    "    n_negative_samples=n_negative_samples,\n",
    "    optimizer=optimizer,\n",
    "    lr=lr,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Feel free to explore other models by changing the hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SHOPPER model can integrate store effects as well as seasonality. Check the documentation if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "shopper.instantiate(n_items=n_items)\n",
    "\n",
    "# Train the model\n",
    "history = shopper.fit(trip_dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"train_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training of SHOPPER model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with SHOPPER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations = 2\n",
    "\n",
    "# You can choose how many basket permuations are used to evaluate the model\n",
    "nll = shopper.evaluate(dataset, n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean negative log-likelihood on the dataset: {nll:.4f}.\")\n",
    "\n",
    "print(\"\\nWe can see that the more complex the model, the lower the negative log-likelihood.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute various utilities and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item utilities\n",
    "item_batch_inference=np.array([2, 0, 4])\n",
    "basket_inference = np.array([1, 3])\n",
    "price_inference = 5.\n",
    "available_items_inference = np.ones(dataset.n_items)\n",
    "available_items_inference[4] = 0  # Consider that item 4 is not available during inference\n",
    "assortment_inference = np.array(\n",
    "    [\n",
    "        item_id for item_id in dataset.get_all_items() if available_items_inference[item_id] == 1\n",
    "    ]\n",
    ")\n",
    "\n",
    "item_utilities = shopper.compute_batch_utility(\n",
    "    item_batch=item_batch_inference,\n",
    "    basket_batch=np.tile(basket_inference, (3, 1)),\n",
    "    store_batch=np.array([0]), # 0 if not defined\n",
    "    week_batch=np.array([0]), # 0 if not defined\n",
    "    price_batch=np.tile(price_inference, 3),\n",
    "    available_item_batch=np.tile(available_items_inference, (3, 1)),\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Considering the assortment (ie the set of available items) {assortment_inference} with prices {price_inference},\",\n",
    "    f\"and a basket with the items {basket_inference}.\\n\",\n",
    "    f\"Under these circumstances, the utility of the selected items are:\"\n",
    ")\n",
    "for i, item_id in enumerate(item_batch_inference):\n",
    "    if item_id == 0:\n",
    "        print(f\"    - Item {item_id} (checkout item): {item_utilities[i]:.4f}\")\n",
    "    else:\n",
    "        print(f\"    - Item {item_id}: {item_utilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item likelihoods\n",
    "item_batch=np.array([2, 0, 4])\n",
    "item_likelihoods = shopper.compute_item_likelihood(\n",
    "    basket=basket_inference,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    store=0,  # 0 if not defined\n",
    "    week=0,  # 0 if not defined\n",
    "    prices=price_inference,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Considering the assortment (ie the set of available items) {assortment_inference} with prices {price_inference},\",\n",
    "    f\"and a basket with the items {basket_inference}.\\n\",\n",
    "    f\"Under these circumstances, the likelihoods that each item will be the next item added to the basket are:\"\n",
    ")\n",
    "for i, item_id in enumerate(dataset.get_all_items()):\n",
    "    if item_id == 0:\n",
    "        print(f\"    - Item {item_id} (checkout item, the customer decides to end his shopping trip): {item_likelihoods[i]:.4f}\")\n",
    "    else:\n",
    "        print(f\"    - Item {item_id}: {item_likelihoods[i]:.4f}\")\n",
    "print(f\"\\nN.B.: The item likelihoods sum to {np.sum(item_likelihoods):.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered basket likelihood\n",
    "basket_ordered = np.array([1, 3, 0])\n",
    "basket_ordered_likelihood = shopper.compute_ordered_basket_likelihood(\n",
    "    basket=basket_ordered,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    store=0,\n",
    "    week=0,\n",
    "    prices=price_inference,\n",
    ")\n",
    "\n",
    "print(f\"Likelihood for ordered basket {basket_ordered}: {basket_ordered_likelihood:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Unordered) basket likelihood\n",
    "n_permutations = 2\n",
    "\n",
    "basket = np.array([1, 3, 0])\n",
    "basket_likelihood = shopper.compute_basket_likelihood(\n",
    "    basket=basket,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    store=0,\n",
    "    week=0,\n",
    "    prices=price_inference,\n",
    "    n_permutations=n_permutations,\n",
    ")\n",
    "print(f\"Likelihood for (unordered) basket {basket}: {basket_likelihood:.4f} (with {n_permutations} permutations to approximate all possible orders).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] SHOPPER: A Probabilistic Model of Consumer Choice with Substitutes and Complements, Ruiz, F. J. R.; Athey, S.; Blei, D. M. (2019), Annals of Applied Statistic\n",
    "(URL: https://arxiv.org/abs/1711.03560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
