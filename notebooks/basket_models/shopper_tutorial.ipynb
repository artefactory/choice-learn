{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to basket modelling with SHOPPER\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/artefactory/choice-learn/blob/main/notebooks/basket_models/shopper_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a synthetic dataset to demonstrate how to use the SHOPPER model [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary requirements\n",
    "\n",
    "# If you run this notebook on Google Colab, or in standalone mode, you need to install the required packages.\n",
    "# Uncomment the following lines:\n",
    "\n",
    "# !pip install choice-learn\n",
    "\n",
    "# If you run the notebook within the GitHub repository, you need to run the following lines, that can skipped otherwise:\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from choice_learn.basket_models.trip_dataset import Trip, TripDataset\n",
    "from choice_learn.basket_models.shopper import Shopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all physical GPUs\n",
    "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"Available physical GPUs: {physical_gpus}\")\n",
    "# Select GPUs to use\n",
    "selected_gpus = []  # Choose the GPUs you want to use ([] = CPU)\n",
    "# Set the selected GPUs to be visible\n",
    "tf.config.set_visible_devices(selected_gpus, \"GPU\")\n",
    "# Verify the visible GPUs\n",
    "visible_gpus = tf.config.get_visible_devices(\"GPU\")\n",
    "print(f\"Visible GPUs: {visible_gpus}\")\n",
    "\n",
    "# Limit GPU memory growth\n",
    "if physical_gpus:\n",
    "  try:\n",
    "    for gpu in physical_gpus:\n",
    "      # Allocate only as much GPU memory as needed for the runtime allocations\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple dataset where we have only six items sold in two different stores.\\\n",
    "- The first store sells items [0, 1, 2, 3, 4] and has observed baskets [0, 1], [2], [1, 3, 4]\n",
    "- The second store sells items [0, 1, 3, 5] and has observed baskets [0, 1], [3, 5]\n",
    "\n",
    "Let's say that each basket has been seen 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = 6\n",
    "assortment_store_1 = np.array([1, 1, 1, 1, 1, 0])\n",
    "assortment_store_2 = np.array([1, 1, 0, 1, 0, 1])\n",
    "\n",
    "assortments = np.array([assortment_store_1, assortment_store_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(n_items) if assortment_store_1[i]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Assortments are encoded as availability matrices indicating the availability (1) or not (0) of the products:\\n{assortments=}\\n\")\n",
    "print(\n",
    "    \"Here, the variable 'assortments' can be read as:\\n\",\n",
    "    f\"- Assortment 1 = {[i for i in range(n_items) if assortment_store_1[i]==1]}\\n\",\n",
    "    f\"- Assortment 2 = {[i for i in range(n_items) if assortment_store_2[i]==1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_baskets = 100\n",
    "\n",
    "purchases_stores_1 =[[0, 1], [2], [1, 3, 4]]\n",
    "purchases_stores_2 = [[0, 1], [3, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our synthetic data, let's transform it as a TripDataset that will be fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's consider totally random prices for the products\n",
    "\n",
    "# First we create a list of Trip objects:\n",
    "trips_list = []\n",
    "\n",
    "unique_id = 0\n",
    "for i in range(num_baskets):\n",
    "    trip = Trip(id=unique_id,\n",
    "    purchases=purchases_stores_1[0],\n",
    "    prices=np.random.uniform(1, 10, n_items),\n",
    "    assortment=0)\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(id=unique_id,\n",
    "    purchases=purchases_stores_1[1],\n",
    "    prices=np.random.uniform(1, 10, n_items),\n",
    "    assortment=0)\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(id=unique_id,\n",
    "    purchases=purchases_stores_1[2],\n",
    "    prices=np.random.uniform(1, 10, n_items),\n",
    "    assortment=0)\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(id=unique_id,\n",
    "    purchases=purchases_stores_2[0],\n",
    "    prices=np.random.uniform(1, 10, n_items),\n",
    "    assortment=1)\n",
    "    trips_list.append(trip)\n",
    "\n",
    "    trip = Trip(id=unique_id,\n",
    "    purchases=purchases_stores_2[1],\n",
    "    prices=np.random.uniform(1, 10, n_items),\n",
    "    assortment=1)\n",
    "    trips_list.append(trip)\n",
    "\n",
    "dataset = TripDataset(trips=trips_list, assortments=assortments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Shopper models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit several SHOPPER models with different utility formulas taking into account different effects (price elasticity, seasonality, etc.). We will use the same learning rate and number of epochs for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# Preferences and price effects are represented by latent variables of size 4 and 3, respectively.\n",
    "latent_sizes = {\"preferences\": 4, \"price\": 3}\n",
    "# We use 2 negative samples for each positive sample during the training phase.\n",
    "n_negative_samples = 2\n",
    "optimizer = \"adam\"\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: items fixed effect + items interactions + price effects\n",
    "shopper = Shopper(\n",
    "    item_popularity=False,\n",
    "    price_effects=True,\n",
    "    seasonal_effects=False,\n",
    "    think_ahead=False,\n",
    "    latent_sizes=latent_sizes,\n",
    "    n_negative_samples=n_negative_samples,\n",
    "    optimizer=optimizer,\n",
    "    lr=lr,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Feel free to explore other models by changing the hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shopper model can integrate customer effects as well as seasonality. Check the documentation if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "shopper.instantiate(n_items=n_items)\n",
    "\n",
    "# Train the models\n",
    "history = shopper.fit(trip_dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history[\"train_loss\"], label=f\"1st model: basic utility formula\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training of SHOPPER models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with SHOPPER models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the models on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_permutations = 2\n",
    "\n",
    "# You can choose how many basket permuations are used to evaluate the model\n",
    "nll = shopper.evaluate(dataset, n_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean negative log-likelihood on the dataset:\\n\",\n",
    "    f\"- 1st model: {nll:.4f}\\n\",\n",
    ")\n",
    "\n",
    "print(\"\\nWe can see that the more complex the model, the lower the negative log-likelihood.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute various utilities and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item utilities\n",
    "item_batch_inference=np.array([2, 0, 4])\n",
    "basket_inference = np.array([1, 3])\n",
    "price_inference = 5.\n",
    "available_items_inference = np.ones(dataset.n_items)\n",
    "available_items_inference[4] = 0  # Consider that item 4 is not available during inference\n",
    "assortment_inference = np.array(\n",
    "    [\n",
    "        item_id for item_id in dataset.get_all_items() if available_items_inference[item_id] == 1\n",
    "    ]\n",
    ")\n",
    "\n",
    "item_utilities = shopper.compute_batch_utility(\n",
    "    item_batch=item_batch_inference,\n",
    "    basket_batch=np.tile(basket_inference, (3, 1)),\n",
    "    customer_batch=np.array([0]), # 0 if not defined\n",
    "    week_batch=np.array([0]), # 0 if not defined\n",
    "    price_batch=np.tile(price_inference, 3),\n",
    "    available_item_batch=np.tile(available_items_inference, (3, 1)),\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Considering the assortment (ie the set of available items) {assortment_inference} with prices {price_inference},\\n\",\n",
    "    f\"and a basket with the items {basket_inference},\\n\",\n",
    "    f\"Under these circumstances, the utility of the selected items are:\\n\"\n",
    ")\n",
    "for i, item_id in enumerate(item_batch_inference):\n",
    "    if item_id == 0:\n",
    "        print(f\"- Item {item_id} (checkout item): {item_utilities[i]:.4f}\")\n",
    "    else:\n",
    "        print(f\"- Item {item_id}: {item_utilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item likelihoods\n",
    "item_batch=np.array([2, 0, 4])\n",
    "item_likelihoods = shopper.compute_item_likelihood(\n",
    "    basket=basket_inference,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    customer=0,  # 0 if not defined\n",
    "    week=0,  # 0 if not defined\n",
    "    prices=price_inference,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Considering the assortment (ie the set of available items) {assortment_inference} with prices {price_inference},\\n\",\n",
    "    f\"and a basket with the items {basket_inference},\\n\",\n",
    "    f\"Under these circumstances, the likelihoods that each item will be the next item he is going to add to his basket are:\\n\"\n",
    ")\n",
    "for i, item_id in enumerate(dataset.get_all_items()):\n",
    "    if item_id == 0:\n",
    "        print(f\"- Item {item_id} (checkout item, the customer decides to end his shopping trip): {item_likelihoods[i]:.4f}\")\n",
    "    else:\n",
    "        print(f\"- Item {item_id}: {item_likelihoods[i]:.4f}\")\n",
    "print(f\"\\nN.B.: The item likelihoods sum to {np.sum(item_likelihoods):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered basket likelihoods\n",
    "basket_ordered = np.array([1, 3, 0])\n",
    "basket_ordered_likelihood = shopper.compute_ordered_basket_likelihood(\n",
    "    basket=basket_ordered,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    customer=0,\n",
    "    week=0,\n",
    "    prices=price_inference,\n",
    ")\n",
    "\n",
    "print(f\"Likelihood for ordered basket {basket_ordered}: {basket_ordered_likelihood:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unordered basket likelihoods\n",
    "n_permutations = 2\n",
    "\n",
    "basket_unordered = np.array([1, 3, 0])\n",
    "basket_unordered_likelihood = shopper.compute_unordered_basket_likelihood(\n",
    "    basket=basket_unordered,\n",
    "    available_items=available_items_inference,  # Consider all items available\n",
    "    customer=0,\n",
    "    week=0,\n",
    "    prices=price_inference,\n",
    "    n_permutations=n_permutations,\n",
    ")\n",
    "print(f\"Likelihood for unordered basket {basket_unordered}: {basket_unordered_likelihood:.4f} (with {n_permutations} permutations to approximate all possible orders)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] SHOPPER: A Probabilistic Model of Consumer Choice with Substitutes and Complements, Ruiz, F. J. R.; Athey, S.; Blei, D. M. (2019), Annals of Applied Statistic\n",
    "(URL: https://arxiv.org/abs/1711.03560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
