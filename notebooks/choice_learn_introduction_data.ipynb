{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to choice-learn's data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to ChoiceDataset\n",
    "\n",
    "Choice-Learn's ChoiceDataset aims at being able to handle large datasets, typically by limiting the usage of memory to store several times the same feature. Its structure is made to fit a choice modelling setup it is needed to estimate choice models weights. \n",
    "This notebook introduces how the package handles data. Here is a summary of the different points that will be adressed:\n",
    "\n",
    "## Summary\n",
    "\n",
    "- [**Introduction**](#an-introduction-to-choicedataset)\n",
    "    - [Example dataset: SwissMetro](#our-example-dataset-swissmetro)\n",
    "    - [The different types of data](#the-different-type-of-data)\n",
    "- [**ChoiceDataset's Instantiation from a single DataFrame**]()\n",
    "    - [Wide format](#creating-a-choicedataset-from-a-wide-dataframe)\n",
    "    - [Long format](#creating-a-choicedataset-from-a-long-dataframe)\n",
    "- [**ChoiceDataset's Instantiation from separate objects**](#instantiation-from-different-objects)\n",
    "    - [Specifying each data type](#separating-data-types)\n",
    "    - [Stacking features](#stacking-features)\n",
    "- [**How to use the ChoiceDataset?**](#using-the-choicedataset-object)\n",
    "    - [Estimating choice models](#estimating-choice-models)\n",
    "    - [Slicing into batches](#slicing-and-batching)\n",
    "- [**Further optimizing RAM usage**]())\n",
    "    - [The FeaturesStorage object]()\n",
    "    - [Complete example of FeaturesStorage use]()\n",
    "    - [Specific example of the OneHotStorage]()\n",
    "- [**List of Ready-To-Use datasets**](#ready-to-use-datasets)\n",
    "- [**References**](#references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import ChoiceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our example dataset: SwissMetro\n",
    "\n",
    "The SwissMetro[2] is a well-known dataset used to illustrate choice modelling. The dataset is provided with the Choice-Learn package and can be downloaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.datasets import load_swissmetro\n",
    "\n",
    "swissmetro_df = load_swissmetro(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SwissMetro is a collection of answers to a survey about mode transportation choice in Switzerland. Before building a costly new public transport line the government decided to better understand the needs of the future customers.\n",
    "A complete description of the dataset and the columns can be found [here](). We will use a subset of the information during the tutorial.\n",
    "\n",
    "<ins>**Available Modes:**</ins>\n",
    "- The customer car, 'CAR'\n",
    "- The current, existing train, 'TRAIN'\n",
    "- The potentially future SwissMetro, 'SM'\n",
    "\n",
    "<ins>**Columns:**</ins>\n",
    "- PURPOSE: What is the customer's travel purpose:\n",
    "- AGE: The customer's age category\n",
    "- mode_AV: Whether the mode is available (1) or not (0)\n",
    "- mode_TT: The mode travel time\n",
    "- mode_CO: The mode cost\n",
    "- CHOICE: the transport mode chosen by the customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_columns = [\"PURPOSE\", \"AGE\", \"ORIGIN\", \"CAR_AV\", \"TRAIN_AV\", \"SM_AV\", \"CAR_TT\",\n",
    "                \"TRAIN_TT\", \"SM_TT\", \"CAR_CO\", \"TRAIN_CO\", \"SM_CO\", \"CHOICE\"]\n",
    "swissmetro_df = swissmetro_df[kept_columns]\n",
    "swissmetro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different type of data\n",
    "\n",
    "We can split the columns into three distincts categories that are common to most choice modelling use-cases:\n",
    "\n",
    "- Choices - or outputs of our model: it's what we want to predict\n",
    "- Features - or inputs of our model\n",
    "- Availabilities - or the description of the set among which the customer chooses\n",
    "\n",
    "Going further, we have two types of features: the features describing the customer and the features describing the mean of transportation. Those are the four types of data that can be specified in a ChoiceDataset.\n",
    "\n",
    "\n",
    "**Vocabulary:**\n",
    "\n",
    "<ins>*Items*</ins> represent a product, an alternative that can be chosen by the customer at some point.\n",
    "\n",
    "\n",
    "Throughout Choice-Learn examples and code here is the naming of our four types of data:\n",
    "\n",
    "- **choices:** which item has been chosen among all availables\n",
    "\n",
    "- **fixed_features_by_choice:** It represents all the features that might change from one choice to another and that are **common** to all items (e.g. day of week, customer features, etc...).\n",
    "  \n",
    "- **items_features_by_choice:** The features each of the available item for a choice (e.g. prices might change from one choice to another and are specific to each sold item).\n",
    "  \n",
    "- **available_items_by_choice:** For each choice it represents whether each item is proposed to the customer (1.) or not (0.).\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "| index | feature  | typical shape  |  Example   | Taken Values |\n",
    "|---|---|---|---|---|\n",
    "| 1 | fixed_features_by_choice | (n_choices, n_features) | customer age, day of week | float, int |\n",
    "| 2 | items_features_by_choice | (n_choices, n_items, n_items_features) | price | float, int |\n",
    "| 3 | available_items_by_choice | (n_choices, n_items) | | 1.(av) or 0. (not av.) |\n",
    "| 4 | choices | (n_choices,) | | int: index of chosen item |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on: example from a pandas' DataFrame\n",
    "\n",
    "The easiest way create a ChoiceDataset is to use a pandas DataFrame.\n",
    "\n",
    "First, here is a small explanation about wide vs long format, in case you have never heard about it, from [Wikipedia](https://en.wikipedia.org/wiki/Wide_and_narrow_data).\n",
    "\n",
    "*Long (or narrow) Format:*  One column containing all the values and another column listing the context of the value\\\n",
    "*Wide Format:* Each different data variable in a separate column.\n",
    "\n",
    "<table>\n",
    "<tr><th>Example Long Format: </th><th>Example Wide Format:</th></tr>\n",
    "\n",
    "<tr><td>\n",
    "\n",
    "| choice id | item | price | availability | choice |\n",
    "|---|---|---|---|---|\n",
    "| 1 | A | 2.0 | 1 | 1 |\n",
    "| 1 | B | 6.0 | 1 | 0 |\n",
    "| 2 | A | 1.5 | 1 | 0 |\n",
    "| 2 | B | 5.5 | 1 | 1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "| choice id | price_A | price_B | availability_A | availability_B | choice |\n",
    "|---|---|---|---|---|---|\n",
    "| 1 | 2.0 | 6.0 | 1 | 1 | A |\n",
    "| 2 | 1.5 | 5.5 | 1 | 1 | B |\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "Choice-Learn handles both formats, but slightly differently:\\\n",
    "- example for [wide](#creating-a-choicedataset-from-a-wide-dataframe) format\n",
    "- example for [long](#creating-a-choicedataset-from-a-long-dataframe) format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ChoiceDataset from a wide DataFrame\n",
    "\n",
    "Our example dataframe on SwissMetro is on the wide format. Each row indicates a choice and each item has its specific features columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset.from_single_wide_df(\n",
    "    # The main DataFrame\n",
    "    df=swissmetro_df,\n",
    "    # The names of the items, will be used to find columns and organize them\n",
    "    items_id=[\"TRAIN\", \"SM\", \"CAR\"],\n",
    "\n",
    "    # The column containing the choices\n",
    "    choices_column=\"CHOICE\",\n",
    "    # How the choices are encoded: item_index means that the choice is the index of the item in the items_id list\n",
    "    choice_format=\"item_index\",\n",
    "\n",
    "    # Columns for fixed_features_by_choice\n",
    "    fixed_features_by_choice_columns=[\"PURPOSE\", \"AGE\"],\n",
    "\n",
    "    # Columns for items_features_by_choice\n",
    "    # They will be reconstructed as item_id + delimiter + feature_suffix\n",
    "    items_features_by_choice_suffixes=[\"CO\", \"TT\"],\n",
    "    # Same with availabilities\n",
    "    available_items_by_choice_suffix=\"AV\",\n",
    "    delimiter=\"_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**\n",
    "\n",
    "choice_format: \"item_index\" or \"item_id\"\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>\"item_index\" </th><th>\"item_id\"</th></tr>\n",
    "\n",
    "<tr><td>\n",
    "\n",
    "| choice_column|\n",
    "|---|\n",
    "| 0 |\n",
    "| 1 |\n",
    "| 0 |\n",
    "| 2 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "| choice_column|\n",
    "|---|\n",
    "| \"TRAIN\" |\n",
    "| \"SM\" |\n",
    "| \"TRAIN\" |\n",
    "| \"CAR\" |\n",
    "\n",
    "</td></tr> </table>\n",
    "\n",
    "items_features_by_choice and available_items_by_choice:\n",
    "\n",
    "It is possible to precise:\n",
    "- Suffixes: in this case the column used will be \"item_id\" + \"delimiter\" + \"suffix\"\n",
    "- Prefixes: in this case the column used will be \"prefix\" + \"delimiter\" + \"item_id\"\n",
    "- Columns: each item's features in list. In this case it is you duty to ensure coherence in terms of items and features orders. For our example it would be:\n",
    "\n",
    "    ```python\n",
    "    items_features_by_choice_columns=[[\"TRAIN_CO\", \"TRAIN_TT\"], [\"SM_CO\", \"SM_TT\"], [\"CAR_CO\", \"CAR_TT\"]],\n",
    "    available_items_by_choice_columns=[\"TRAIN_AV\", \"SM_AV\", \"CAR_AV\"],\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ChoiceDataset from a long DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = []\n",
    "for n_row, row in swissmetro_df.iterrows():\n",
    "    df_dict = {\n",
    "        \"PURPOSE\": [row[\"PURPOSE\"]]*3,\n",
    "        \"AGE\": [row[\"AGE\"]]*3,\n",
    "        \"ITEM_ID\": [],\n",
    "        \"AV\": [],\n",
    "        \"TT\": [],\n",
    "        \"CO\": [],\n",
    "        \"CHOICE\": [],\n",
    "        \"CHOICE_ID\": [n_row]*3,\n",
    "    }\n",
    "\n",
    "    for item_index, item_id in enumerate([\"TRAIN\", \"SM\", \"CAR\"]):\n",
    "        if item_index == row.CHOICE:\n",
    "            df_dict[\"CHOICE\"].append(1)\n",
    "        else:\n",
    "            df_dict[\"CHOICE\"].append(0)\n",
    "        \n",
    "        df_dict[\"ITEM_ID\"].append(item_id)\n",
    "        df_dict[\"AV\"].append(row[f\"{item_id}_AV\"])\n",
    "        df_dict[\"TT\"].append(row[f\"{item_id}_TT\"])\n",
    "        df_dict[\"CO\"].append(row[f\"{item_id}_CO\"])\n",
    "    long.append(pd.DataFrame(df_dict))\n",
    "long_df = pd.concat(long, axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset.from_single_long_df(\n",
    "    df=long_df,\n",
    "    choices_column=\"CHOICE\",\n",
    "    items_id_column=\"ITEM_ID\",\n",
    "    choices_id_column=\"CHOICE_ID\",\n",
    "    \n",
    "    fixed_features_by_choice_columns=[\"PURPOSE\", \"AGE\"],\n",
    "    items_features_by_choice_columns=[\"TT\", \"CO\"],\n",
    "    available_items_by_choice_column=\"AV\",\n",
    "    \n",
    "    choice_format=\"one_zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**\n",
    "\n",
    "choice_format: \"one_zero\" or \"item_id\"\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr><th>\"one_zero\" </th><th>\"item_id\"</th></tr>\n",
    "\n",
    "<tr><td>\n",
    "\n",
    "| choice_id_column | item_id_column | choice_column|\n",
    "|---|---|---|\n",
    "| 1 | \"CAR\" | 0 |\n",
    "| 1 | \"SM\" | 1 |\n",
    "| 2 | \"CAR\" | 1 |\n",
    "| 2 | \"SM\" | 0 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "| choice_id_column | item_id_column | choice_column|\n",
    "|---|---|---|\n",
    "| 1 | \"CAR\" | \"SM\" |\n",
    "| 1 | \"SM\" | \"SM\" |\n",
    "| 2 | \"CAR\" | \"CAR\" |\n",
    "| 2 | \"SM\" | \"CAR\" |\n",
    "\n",
    "</td></tr> </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation from different objects\n",
    "\n",
    "For RAM optimization purposes or just because of the format of the data source, it might happen that a dataset is split into separate files. You can instantiate a ChoiceDataset keeping this structure, saving time to concatenate everything.\\\n",
    "You can work either with pandas.DataFrames or numpy.ndarrays.\n",
    "\n",
    "### Separating data types\n",
    "The four distinct data types: choices, fixed_features_by_choice, items_features_by_choice, available_items_by_choice can be manually given to the ChoiceDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas.DataFrames\n",
    "dataset = ChoiceDataset(\n",
    "    choices=df[\"CHOICE\"],\n",
    "    fixed_features_by_choice=df[[\"PURPOSE\", \"AGE\"]],\n",
    "    items_features_by_choices=long_df[[\"CO\", \"TT\"]]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy.ndarrays\n",
    "# Be aware of items_features_by_choices shape that is (n_choices, n_items, n_features)\n",
    "\n",
    "items_features_by_choice = np.stack([swissmetro_df[[\"CAR_CO\", \"CAR_TT\"]].to_numpy(),\n",
    "                                      swissmetro_df[[\"SM_CO\", \"SM_TT\"]].to_numpy(),\n",
    "                                      swissmetro_df[[\"TRAIN_CO\", \"TRAIN_TT\"]].to_numpy()],\n",
    "                                      axis=1)\n",
    "fixed_features_by_choice = swissmetro_df[[\"PURPOSE\", \"AGE\"]].to_numpy()\n",
    "available_items_by_choice = swissmetro_df[[\"CAR_AV\", \"SM_AV\", \"TRAIN_AV\"]].to_numpy()\n",
    "\n",
    "print(\"The data shapes are:\")\n",
    "print(f\"choices: {swissmetro_df['CHOICE'].shape}\")\n",
    "print(f\"fixed_features_by_choice: {fixed_features_by_choice.shape}\")\n",
    "print(f\"items_features_by_choice: {items_features_by_choice.shape}\")\n",
    "print(f\"available_items_by_choice: {available_items_by_choice.shape}\")\n",
    "\n",
    "dataset = ChoiceDataset(\n",
    "    choices=swissmetro_df[\"CHOICE\"].to_numpy(),\n",
    "    fixed_features_by_choice=fixed_features_by_choice,\n",
    "    items_features_by_choices=items_features_by_choice,\n",
    "    available_items_by_choice=available_items_by_choice,\n",
    "\n",
    "    # Features names can optionally be provided\n",
    "    # the structure of data and names must match\n",
    "    fixed_features_by_choice_names=[\"PURPOSE\", \"AGE\"],\n",
    "    items_features_by_choice_names=[\"CO\", \"TT\"],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Features\n",
    "\n",
    "It is allowed to specify more than one features object by wrapping them in a tuple. This structure is kept inside the ChoiceDataset object as well as with the slicing into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas.DataFrames - Similar with np.ndarrays\n",
    "dataset = ChoiceDataset(\n",
    "    choices=swissmetro_df[\"CHOICE\"],\n",
    "    fixed_features_by_choice=(swissmetro_df[[\"PURPOSE\"]], swissmetro_df[[\"AGE\"]]),\n",
    "    items_features_by_choices=(long_df[[\"CO\"]], long_df[[\"TT\"]]),\n",
    "    available_items_by_choice=swissmetro_df[[\"CAR_AV\", \"SM_AV\", \"TRAIN_AV\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the ChoiceDataset object\n",
    "\n",
    "### Estimating choice models\n",
    "\n",
    "With your ChoiceDataset instantiated, it can be used as is to fit choice models. An illustration can be found in the conditional MNL introduction [notebook]().\n",
    "\n",
    "### Slicing and batching\n",
    "\n",
    "ChoiceDatasets are indexed by choice, meaning that accessing the i-th index corresponds to the i-th choice. Differently said it is the i-th value of the object given as 'choices' in the ChoiceDataset instantiation.\n",
    "\n",
    "A ChoiceDataset can be sliced commonly using the [.] Python method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset = dataset[[0, 2, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub_dataset will be a ChoiceDataset containing only the 0th, 2nd and 4th choice of dataset. The other data (fixed_featurs_by_choice, items_features_by_choice and available_items_by_choice) are also kept and sliced accordingly.\n",
    "\n",
    "In order to only get a chunk of data, it is possible to use .batch[.]. It will return the different data types sliced along choices in a raw np.ndarray format. Use .iter_batch() to iterate over all data in the ChoiceDataset by setting the batch_size argument to control the length of each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataset.batch[[0, 2, 4]]\n",
    "print(\"\")\n",
    "for batch in dataset.iter_batch(batch_size=1024):\n",
    "    print(\"Num choices:\", len(batch[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced use: the FeatureStorage & RAM optimization\n",
    "\n",
    "In many use-cases we will see features or group of features values being repeated over the dataset. For example if one customer comes several time, its features will be repeated. With One-Hot representations, it can create memory-heavy repetitions.\\\n",
    "Choice-Learn introduces FeaturesStorage and FeaturesByIds in order to limit the memory usage before accessing a batch of data.\n",
    "\n",
    "## FeaturesStorage, why should I use it ?\n",
    "If you are not using a large dataset with many features you can pass this part. FeaturesStorage are here if you want to further optimize your memory consumption and if you take some time to understand it.\\\n",
    "It is mainly built to work well with ChoiceDataset, but here is a small introduction on how it works:\n",
    "\n",
    "**/!\\ Disclaimer**\n",
    "For the sake of the example, some features will be introduced and created. They are totally made up and do notexist in the original - and true - version of the SwissMetro Dataset.\n",
    "\n",
    "Let's consider the survey that happened in the three cantons: Geneva, Berne and Zürich. Now we want to integrate localization features.\n",
    "\n",
    "| Canton | Inhabitants (M) | Surface (km^2) | Origin Code |\n",
    "|---|---|---|---|\n",
    "| Geneva | 0.5 | 282 | 25 |\n",
    "| Zürich | 1.5 | 1729 | 1 |\n",
    "| Berne | 1.0 | 5959 | 2 |\n",
    "\n",
    "A naive way to integreate those features is to add them as 'fixed_features_by_choice'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering cantons\n",
    "swiss_df = swissmetro_df.loc[swissmetro_df.ORIGIN.isin([1, 2, 25])]\n",
    "\n",
    "# Adding features\n",
    "swiss_df[\"CANTON_SURFACE\"] = swiss_df.apply(lambda row: {1: 1729, 2: 5959, 25: 282}[row.ORIGIN], axis=1)\n",
    "swiss_df[\"CANTON_INHAB\"] = swiss_df.apply(lambda row: {1: 1.5, 2: 1.0, 25: 0.5}[row.ORIGIN], axis=1)\n",
    "\n",
    "dataset = ChoiceDataset.from_single_wide_df(\n",
    "    df=swiss_df,\n",
    "    items_id=[\"TRAIN\", \"SM\", \"CAR\"],\n",
    "\n",
    "    choices_column=\"CHOICE\",\n",
    "    choice_format=\"item_index\",\n",
    "\n",
    "    # The new features are added here compared to example above\n",
    "    fixed_features_by_choice_columns=[\"PURPOSE\", \"AGE\", \"CANTON_SURFACE\", \"CANOTN_INHAB\"],\n",
    "    items_features_by_choice_suffixes=[\"CO\", \"TT\"],\n",
    "    available_items_by_choice_suffix=\"AV\",\n",
    "    delimiter=\"_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main caveat is that the same features are repeated over the rows of the dataset. If we consider hundreds of stores on several millions - or billions - of choices, it would become... unreasonable!\\\n",
    "One idea is to regroup the features behind an ID (the canton id for example) and to reconstruct the features only in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import FeaturesStorage\n",
    "\n",
    "origin_canton_features = {1: [1.5, 1729], 2: [1.0, 5959], 25: [0.5, 282]}\n",
    "canton_storage = FeaturesStorage(values=origin_canton_features, name=\"ORIGIN\") # Remark that the name matches the ID column name in the DF\n",
    "\n",
    "# Let's see how we can use this bad boy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is basically a Python dictionnary with a wrap-up to easily get batches of data.\\\n",
    "You can ask for a sequence of features with .batch. It works with the keys of our dictionnary that can be int, float, str, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Retrieving features of canton id 1:\")\n",
    "print(canton_storage.batch[1])\n",
    "print(\"Retrieving a batch of features:\")\n",
    "print(canton_storage.batch[[1, 25, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is handy for its transparent use with ChoiceDataset. For it to work well it is needed to:\n",
    "- specify a FeaturesStorage name that matches the feature names given to the ChoiceDataset\n",
    "- match FeaturesStorage ids with the sequence (types and values)\n",
    "- specify the FeaturesStorage objects listed with the features_by_ids argument\n",
    "\n",
    "In our case we call our FeaturesStorage \"supermarket_features\", the ids are now strings, let's maker the sequence match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dataset = ChoiceDataset(choices=swiss_df[\"CHOICE\"],\n",
    "                                fixed_features_by_choice=swiss_df[[\"AGE\", \"PURPOSE\", \"ORIGIN\"]],\n",
    "                                features_by_ids=[canton_storage],\n",
    ")\n",
    "\n",
    "storage_dataset = ChoiceDataset(choices=swiss_df[\"CHOICE\"],\n",
    "                                fixed_features_by_choice=swiss_df[[\"AGE\", \"PURPOSE\", \"ORIGIN\"]].to_numpy(),\n",
    "                                fixed_features_by_choice_names=[\"AGE\", \"PURPOSE\", \"ORIGIN\"],\n",
    "                                features_by_ids=[canton_storage],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ChoiceDataset from this *single* dataframe\n",
    "\n",
    "In order to create the ChoiceDataset from the DataFrame, we need to specify:\n",
    "- the column in which the choice is given\n",
    "- the column where the item is identified \n",
    "- the column where the context is identified\n",
    "- the columns representing the fixed_items_features\n",
    "- the columns representing the contexts_features\n",
    "- the columns representing the contexts_items_features\n",
    "\n",
    "\n",
    "For our Canada Transport example, here is how it should be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset.from_single_long_df(\n",
    "    df=transport_df,\n",
    "    choices_column=\"choice\",\n",
    "    items_id_column=\"alt\",\n",
    "    contexts_id_column=\"case\",\n",
    "    fixed_items_features_columns=[\"is_public\"],\n",
    "    contexts_features_columns=[\"income\", \"urban\", \"dist\"],\n",
    "    contexts_items_features_columns=[\"cost\", \"freq\", \"ovt\", \"ivt\"],\n",
    "    choice_format=\"one_zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last argument, \"choice_format\", precises how the choice is encoded in the dataframe. Currently two modes are availble:\n",
    "\n",
    " - *one_zero*:\n",
    "The choice column contains a 0 when the alternative/item is not chosen in the session and a 1 if it is chosen.\n",
    "This is the case here with Canada Transport.\n",
    " - *item_id*:\n",
    "The choice column contains the id of the choice during the session. The id corresponds to the values used in the column 'items_id_column'.\n",
    "In this case of Canada Transport, the dataframe would need to be:\n",
    "\n",
    "| | case | alt | choice | dist | cost | ivt | ovt | freq | \tincome | urban | noalt | \n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| 1 | 1 | train | car | 83 | 28.25 | 50 | 66 | 4 | 45 | 0 | 2 |\n",
    "| 2 | 1 | car | car | 83 | 15.77 | 61 | 0 | 0 | 45 | 0 | 2 |\n",
    "| 3 | 2 | train | car | 83 | 28.25 | 50 | 66 | 4 | 25 | 0 | 2 |\n",
    "| 4 | 2 | car | car | 83 | 15.77 | 61 | 0 | 0 | 25 | 0 | 2 |\n",
    "| 5 | 3 | train | car | 83 | 28.25 | 50 | 66 | 4 | 70 | 0 | 2 |\n",
    "\n",
    "In the first 5 examples, the chosen transportation is always the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ChoiceDataset is ready !\n",
    "\n",
    "If your DataFrame is in the wide format, you can use the equivalent method *from_single_wide_df*. An example can be found [here](https://github.com/artefactory/choice-learn-private/blob/main/notebooks/dataset_creation.ipynb) on the SwissMetro dataset: \n",
    "\n",
    "You now have three possibilities to continue discovering the choice-learn package:\n",
    "- You can directly go [here]() to the modelling tutorial if you want to understand how a first simple ConditionMNl would be implemented.\n",
    "- You can go [here]() if your dataset is organized differently to see all the different ways to instantiate a ChoiceDataset. In particular it helps if you data is splitted into several DataFrames or if you have another format of data.\n",
    "- Or you can continue this current tutorial to better understand the ChoiceDataset machinery and everything there is to know about it.\n",
    "\n",
    "Whatever your choice, you can also check [here](#ready-to-use-datasets) the list of open source datasets available directly with the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on: example from a NumPy arrays\n",
    "\n",
    "Let's see an example of ChoiceDataset instantiation from numpy arrays.\n",
    "\n",
    "Let's consider three *items* whose *features* are: Size, Weight, price, promotion (simply a boolean to indicate whether it is under promotion).\n",
    "\n",
    "For size and weights, we will store as *fixed items features* as they don't change. For the price and promotion, we will store in the *contexts items features*, since they may change for each context.\n",
    "\n",
    "For the *contexts*, we will consider the customers attributes: Budget and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choices:\n",
    "# Customer 1 bought item 1\n",
    "# Customer 2 bought item 3\n",
    "# Customer 1 bought item 2\n",
    "\n",
    "choices = [0, 2, 1]\n",
    "\n",
    "fixed_items_features = [\n",
    "    [1, 2], # item 1 [size, weight]\n",
    "    [2, 4], # item 2 [size, weight]\n",
    "    [1.5, 1.5], # item 3 [size, weight]\n",
    "]\n",
    "\n",
    "contexts_features = [\n",
    "    [100, 20], # choice 1, customer 1 [budget, age]\n",
    "    [200, 40], # choice 2, customer 2 [budget, age]\n",
    "    [80, 20], # choice 3, customer 1 [budget, age]\n",
    "]\n",
    "\n",
    "contexts_items_features = [\n",
    "    [\n",
    "        [100, 0], # choice 1, Item 1 [price, promotion]\n",
    "        [140, 0], # choice 1, Item 2 [price, promotion]\n",
    "        [200, 0], # choice 1, Item 2 [price, promotion]\n",
    "    ],\n",
    "    [\n",
    "        [100, 0], # choice 2, Item 1 [price, promotion]\n",
    "        [120, 1], # choice 2, Item 2 [price, promotion]\n",
    "        [200, 0], # choice 2, Item 2 [price, promotion]\n",
    "    ],\n",
    "    [\n",
    "        [100, 0], # choice 3, Item 1 [price, promotion]\n",
    "        [120, 1], # choice 3, Item 2 [price, promotion]\n",
    "        [180, 1], # choice 3, Item 2 [price, promotion]\n",
    "    ],\n",
    "]\n",
    "\n",
    "contexts_items_availabilities = [\n",
    "    [1, 1, 1], # All items available at choice 1\n",
    "    [1, 1, 1], # All items available at choice 2\n",
    "    [0, 1, 1], # Item 1 not available at choice 3\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in items_features and contexts_items_features, the features need to be well ordered:\n",
    "- The features are ordered the same for all items\n",
    "- The items are ordered in their index given in choices. This applies in items_features and contexts_items_features\n",
    "\n",
    "\n",
    "**items_features** = [[item1_featureA, item1_featureB, ...], [item2_featureA, item2_featureB, ...], ...]\n",
    "\n",
    "**contexts_items_features** = [[[context1_item1_featureA, ...], [context1_item2_featureA, ...]], [[context2_item1_featureA, ...], [context2_item2_featureA, ...]], ...]\n",
    "\n",
    "**choices** then represent the index of the item: 0 when item1 is chose, 1 when item2, etc..., e.g. [0, 0, 2, 1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChoiceDataset(\n",
    "    choices=choices,\n",
    "    fixed_items_features=fixed_items_features,\n",
    "    fixed_items_features_names=[\"size\", \"weight\"], # You can precise the names of the features if you want\n",
    "    contexts_features=contexts_features,\n",
    "    contexts_features_names=[\"budget\", \"age\"], # same, not mandatory\n",
    "    contexts_items_features=contexts_items_features,\n",
    "    contexts_items_features_names=[\"price\", \"promotion\"], # same, not mandatory\n",
    "    contexts_items_availabilities=contexts_items_availabilities,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "dataset.contexts_items_features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChoiceDataset is indexed by choice. You can use [] to subset it.\n",
    "It is particularly useful for train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "train_index = [0, 1]\n",
    "test_index = [2]\n",
    "train_dataset = dataset[train_index]\n",
    "test_dataset = dataset[test_index]\n",
    "print(\"Train Dataset length:\", len(train_dataset), \"Test Dataset lenght:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access the features you can use the .iloc function with choices indexes \n",
    "It returns the features in this order:\n",
    "\n",
    "- items_features (n_items, n_items_features)\n",
    "- contexts_features (n_choices, n_sessions_features)\n",
    "- contexts_items_features (n_choices, n_items, n_sessions_items_features)\n",
    "- contexts_items_availabilities (n_choices, n_items)\n",
    "- choices (n_choices,)\n",
    "\n",
    "As a reminder, we have as many contexts as we have choices in the dataset !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| index | feature  | shape  |   \n",
    "|---|---|---|\n",
    "| 0 | items_features | (n_items, n_items_features) |\n",
    "| 1 | contexts_features | (n_choices, n_contexts_features) |\n",
    "| 2 | contexts_items_features | (n_choices, n_items, n_contexts_items_features) |\n",
    "| 3 | context_items_availabilities | (n_choices, n_items) |\n",
    "| 4 | choices | (n_choices,) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "contexts_indexes = [0, 1]\n",
    "print(\"Items features:\", train_dataset.batch[contexts_indexes][0])\n",
    "print(\"Contexts features:\", train_dataset.batch[contexts_indexes][1])\n",
    "print(\"Contexts Items features:\", train_dataset.batch[contexts_indexes][2])\n",
    "print(\"Contexts Items Availabilities features:\", train_dataset.batch[contexts_indexes][3])\n",
    "print(\"Contexts Choices:\", train_dataset.batch[contexts_indexes][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the iteration over the dataset you can call the .iter_batch method, with the batch_size argument.\n",
    "\n",
    "Note that batch_size=-1 returns the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "# All the features are given for each session, in order to compute utility and NegativeLogLikelihood\n",
    "for i, batch in enumerate(dataset.iter_batch(batch_size=1)):\n",
    "    print(i, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking features when building the ChoiceDataset**\n",
    "\n",
    "If you need to keep a clear distinction between different features, you can use stacking in the ChoiceDataset. In this case, you need to provide the additional features arrays indexed the same. It is possible to stack: *items_features*, *contexts_features*, *contexts_items_features*.\n",
    "\n",
    "For example if we have two kind of items_features and we do not want them to be within the same np.ndarray we can as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_features_2 = [\n",
    "    [11, 12], # item 1 \n",
    "    [12, 14], # item 2 \n",
    "    [11.5, 11.5], # item 3 \n",
    "]\n",
    "dataset = ChoiceDataset(\n",
    "    # Here items_features specified as a tuple of the two features lists\n",
    "    fixed_items_features=(fixed_items_features, items_features_2),\n",
    "    contexts_features=contexts_features,\n",
    "    contexts_items_features=contexts_items_features,\n",
    "    contexts_items_availabilities=contexts_items_availabilities,\n",
    "    choices=choices,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When indexing or batching your ChoiceDataset, you will now get items_features as a tuple, with elements corresponding to (items_features, items_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "dataset.batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced use: the FeatureStorage & RAM optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced use: the FeatureStorage & RAM optimization\n",
    "\n",
    "## FeaturesStorage, why should I use it ?\n",
    "Regularly, you have features that repeat themselves over several choices. It can happen if you have several times the same customer, if you have store features or if you use OneHot representations... And those are only example.\n",
    "\n",
    "The FeaturesStorage object is designed to help you better handle these cases. It is mainly built to work well with ChoiceDataset, but here is a small introduction on how it works:\n",
    "\n",
    "Let's consider a case where we consider three supermarkets: \n",
    "- supermarket_1 with surface of 100 and 250 average nb of customers\n",
    "- supermarket_2 with surface of 150 and 500 average nb of customers\n",
    "- supermarket_3 with surface of 80 and 100 average nb of customers \n",
    "\n",
    "In each store, we have 4 available products for which we have little information. For the example'sake, let's consider the following utility:\n",
    "$$U(i) = u_i + \\beta_1 \\cdot S_s + \\beta_2 \\cdot C_s$$\n",
    "With $S_s$ the surface of the store and $C_s$ its average number of customers.\n",
    "\n",
    "We want to estimate the base utilities $u_i$ and the two coefficients: $\\beta_1$ and $\\beta_2$.\n",
    "\n",
    "Let's start with creating a ChoiceDataset without the FeaturesStorage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a case where we consider three supermarkets: \n",
    "- supermarket_1 with surface of 100 and 250 average nb of customers\n",
    "- supermarket_2 with surface of 150 and 500 average nb of customers\n",
    "- supermarket_3 with surface of 80 and 100 average nb of customers \n",
    "\n",
    "In each store, we have 4 available products for which we have little information. For the example'sake, let's consider the following utility:\n",
    "$$U(i) = u_i + \\beta_1 \\cdot S_s + \\beta_2 \\cdot C_s$$\n",
    "With $S_s$ the surface of the store and $C_s$ its average number of customers.\n",
    "\n",
    "We want to estimate the base utilities $u_i$ and the two coefficients: $\\beta_1$ and $\\beta_2$.\n",
    "\n",
    "Let's start with creating a ChoiceDataset without the FeaturesStorage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "# Here are our choices:\n",
    "choices = [0, 1, 2, 0, 2, 1, 1, 0, 2, 1, 2, 0, 2, 0, 1, 2, 1, 0]\n",
    "supermarket_features = [[100, 250], [150, 500], [80, 100]]\n",
    "# Now our store sequence of supermarkets is:\n",
    "supermarkets_sequence = [1, 1, 2, 3, 2, 1, 2, 1, 1, 2, 3, 2, 1, 2, 2, 3, 1, 2]\n",
    "\n",
    "# The usual way to store the features would be to create the contexts_features array that contains\n",
    "# the right features:\n",
    "usual_supermarket_features = np.array([supermarket_features[supermarket_id - 1] for supermarket_id in supermarkets_sequence])\n",
    "print(\"Usual Supermakerket Features Shape:\", usual_supermarket_features.shape)\n",
    "\n",
    "# And now we can create our ChoiceDataset:\n",
    "\n",
    "usual_dataset = ChoiceDataset(choices=choices,\n",
    "                              fixed_items_features=np.eye(3),\n",
    "                              contexts_features=usual_supermarket_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our dataset, we only need to create our ChoiceModel and we are good to go. However, it would also be natural to feel unsatisfied because your dataset is not well optimized. Indeed we have repeated the same information several times having a lot of redundant information.\n",
    "\n",
    "If in our small use-case it does not really matter, if we consider hundreds of stores on several millions - or billions - of choices, it would become... unreasonable!\n",
    "\n",
    "Let's now welcome the FeaturesStorage to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import FeaturesStorage\n",
    "\n",
    "features_dict = {f\"supermarket_{i+1}\": supermarket_features[i] for i in range(3)}\n",
    "storage = FeaturesStorage(values=features_dict, name=\"supermarket_features\")\n",
    "\n",
    "# Let's see how we can use this bad boy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is basically a Python dictionnary with a wrap-up to easily get batches of data.\\\n",
    "You can ask for a sequence of features with .batch. It works with the keys of our dictionnary that can be int, float, str, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "print(\"Retrieving features of first supermarket:\")\n",
    "print(storage.batch[\"supermarket_1\"])\n",
    "print(\"Retrieving a batch of features:\")\n",
    "print(storage.batch[[\"supermarket_1\", \"supermarket_2\", \"supermarket_1\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FeaturesStorage is handy for its transparent use with ChoiceDataset. For it to work well you need:\n",
    "- to specify a FeaturesStorage name\n",
    "- to match FeaturesStorage ids with the sequence\n",
    "\n",
    "In our case we call our FeaturesStorage \"supermarket_features\", the ids are now strings, let's maker the sequence match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_supermarkets_sequence = [[f\"supermarket_{i}\"] for i in supermarkets_sequence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create our ChoiceDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dataset = ChoiceDataset(choices=choices,\n",
    "                                contexts_features=str_supermarkets_sequence,\n",
    "                                contexts_features_names=[\"supermarket_features\"],\n",
    "                                fixed_items_features=np.eye(3),\n",
    "                                features_by_ids=[storage],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have paid attention, we have specified the FeaturesStorage in the features_by_ids argument and we HAVE TO match the contexts_features_names column with the name of the Features Storage.\\\n",
    "When calling for a batch of data, the ChoiceDataset will look into the FeaturesStorage call \"supermarket_features\" to match the values in contexts_features with the ones store in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "batch = storage_dataset.batch[0]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])\n",
    "print(\"%-------------------------%\")\n",
    "batch = storage_dataset.batch[[1, 2, 3]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])\n",
    "print(\"%-------------------------%\")\n",
    "batch = storage_dataset.batch[[0, 1, 5]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is mapped as needed. And the great thing is that you can easily mix ''classical'' features with FeaturesStorages.\\\n",
    "Let's add a 'is_week_end' feature to our problem that will also be stored as a contexts_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "contexts_features = pd.DataFrame({\"supermarket_features\": np.array(str_supermarkets_sequence).squeeze(),\n",
    "\"is_week_end\": [0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]})\n",
    "contexts_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the ChoiceDataset\n",
    "storage_dataset = ChoiceDataset(choices=choices,\n",
    "                                contexts_features=contexts_features,\n",
    "                                fixed_items_features=np.eye(3),\n",
    "                                features_by_ids=[storage],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "# And now it's ready\n",
    "batch = storage_dataset.batch[[1, 2, 3]]\n",
    "print(\"Batch Fixed Items Features:\", batch[0])\n",
    "print(\"Batch Contexts Features:\", batch[1])\n",
    "print(\"Batch Choice:\", batch[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific sub-example: the OneHot Storage\n",
    "A recurring usecase is the use of **OneHot** representation of features. The OneHotStorage is built specifically for one-hot encoded features and further improves memory consumption. The storage is to be used the same way as FeaturesStorage, but behind will only keep the index of the one of each element and will consitute the one-hot vector only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import OneHotStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "storage = OneHotStorage(ids=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "print(\"RAM storage of the OneHotStore:\", storage.storage)\n",
    "# When indexing with .batch, we can access the one-hot encoding of the element using its id\n",
    "print(\"One-hot vector batch: storage.batch['a']\", storage.batch[\"a\"])\n",
    "print(\"One-hot vector batch: storage.batch[['a', 'b', 'c', 'c', 'b', 'a']]\")\n",
    "print(storage.batch[[\"a\", \"b\", \"c\", \"c\", \"b\", \"a\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that:**\n",
    "- we use strings as ids for the example, however we recommend to use integers.\n",
    "- FeaturesStorage can be instantiated from dict, np.ndarray, list, pandas.DataFrame, etc...\n",
    "- More in-depth examples and explanations can be found [here](./features_byID_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready-to-use datasets\n",
    "A few well-known open source datasets are directly integrated and the package and can be downloaded in one line:\n",
    "- SwissMetro from Bierlaire et al (2001) [2]\n",
    "- ModeCanada from Koppleman et al. (1993) [1]\n",
    "- The Train dataset from Ben Akiva et al. (1993) [4]\n",
    "- The Heating & Electricity datasets from Kenneth Train [3]\n",
    "- The TaFeng dataset from Kaggle [5]\n",
    "\n",
    "If you feel like another open-source dataset should be included, reach out !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.datasets import load_swissmetro, load_modecanada, load_train, load_heating, load_electricity, load_tafeng\n",
    "\n",
    "canada_choice_dataset = load_modecanada()\n",
    "swissmetro_choice_dataset = load_swissmetro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets can also be downloaded as dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "swissmetro_df = load_swissmetro(as_frame=True)\n",
    "swissmetro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Koppelman et al. (1993), *Application and Interpretation of Nested Logit Models of Intercity Mode Choice*\\\n",
    "[2] Bierlaire, M., Axhausen, K. and Abay, G. (2001), *The Acceptance of Modal Innovation: The Case of SwissMetro*\\\n",
    "[3] Train, K.E. (2003) *Discrete Choice Methods with Simulation.* Cambridge University Press.\\\n",
    "[4] Ben-Akiva M.; Bolduc D.; Bradley M. (1993) *Estimation of Travel Choice Models with Randomly Distributed Values of Time*\\\n",
    "[5] https://www.kaggle.com/datasets/chiranjivdas09/ta-feng-grocery-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
