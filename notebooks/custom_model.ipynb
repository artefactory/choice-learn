{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to customized Choice Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Choice-Learn package aims at providing structure and helpful functions in order to design any choice model. The main idea is to write the utility function and let the package work its magic.\n",
    "It is recommended to read the data tutorial before to understand the ChoiceDataset class.\n",
    "\n",
    "Let's create again a conditional MNL on the ModeCanada just like the example previous example \\ref{}. Only this time we will write the model ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Remove GPU use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the ModeCanada dataset as a ChoiceDataset, see \\ref{} for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from choice_learn.data import ChoiceDataset\n",
    "\n",
    "# TO be transformed to be clearer\n",
    "transport_df = pd.read_csv(\"/data/raw_data/ModeCanada.csv\", index_col=0)\n",
    "\n",
    "# Following torch-Choice guide:\n",
    "transport_df = transport_df.loc[transport_df.noalt == 4]\n",
    "\n",
    "items = [\"air\", \"bus\", \"car\", \"train\"]\n",
    "\n",
    "transport_df[\"oh_air\"] = transport_df.apply(lambda row: 1. if row.alt == items[0] else 0., axis=1)\n",
    "transport_df[\"oh_bus\"] = transport_df.apply(lambda row: 1. if row.alt == items[1] else 0., axis=1)\n",
    "transport_df[\"oh_car\"] = transport_df.apply(lambda row: 1. if row.alt == items[2] else 0., axis=1)\n",
    "transport_df[\"oh_train\"] = transport_df.apply(lambda row: 1. if row.alt == items[3] else 0., axis=1)\n",
    "\n",
    "transport_df.income = transport_df.income.astype(\"float32\")\n",
    "\n",
    "dataset = ChoiceDataset.from_single_df(df=transport_df,\n",
    "                                       items_features_columns=[\"oh_air\",\n",
    "                                                               \"oh_bus\",\n",
    "                                                               \"oh_car\",\n",
    "                                                               \"oh_train\"],\n",
    "                                       sessions_features_columns=[\"income\"],\n",
    "                                       sessions_items_features_columns=[\"cost\",\n",
    "                                                                        \"freq\",\n",
    "                                                                        \"ovt\",\n",
    "                                                                        \"ivt\"],\n",
    "                                       items_id_column=\"alt\",\n",
    "                                       sessions_id_column=\"case\",\n",
    "                                       choices_column=\"choice\",\n",
    "                                       choice_mode=\"one_zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will subclass the parent class ChoiceModel that we need to import. It mainly works with TensorFlow as a backend, it is thus recommended to use  their operation as much as possible. Most NumPy operations have a TensorFlow equivalent. You can look at the documentation here \\ref{}.\n",
    "\n",
    "For our custom model to work, we need to specify:\n",
    "- Weights initialization in __init__()\n",
    "- the utility function in compute_utility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from choice_learn.models.base_model import ChoiceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Coefficients Initialization*\n",
    "\n",
    "Following our utility formula we need four coefficients vectors:\n",
    "- $\\beta^{inter}$ has 3 values\n",
    "- $\\beta^{price}$, $\\beta^{freq}$, $\\beta^{ovt}$ are regrouped and each has one value, shared by all items\n",
    "- $\\beta^{income}$ has 3 values\n",
    "- $\\beta^{ivt}$ has 4 values\n",
    "\n",
    "### *Utility Computation*\n",
    "\n",
    "In the method compute_utility, we need to define how to estimate each item utility for each session using  the features and initialized weights.\n",
    "The arguments of the function are each features type of the ChoiceDataset class:\n",
    "\n",
    "| Order | Argument | shape | Features for ModeCanada| \n",
    "|---|---|---|---|\n",
    "| 1 | items_features | (n_items, n_items_features) | Items OneHot vectors | \n",
    "| 2 | sessions_features | (n_sessions, n_sessions_features) | Customer Income | \n",
    "| 3 | sessions_items_features | (n_sessions, n_items, n_sessions_items_features) | Cost, Freq, Ivt, Ovt values of each mode | \n",
    "| 4 | sessions_items_availabilities | (n_sessions, n_items) | Not Used | \n",
    "| 5 | choices | (n_sessions, ) | Not Used | \n",
    "\n",
    "The method needs to return the utilities, in the form of a matrix of shape (n_sessions, n_items), reprenting the utility of each item for each session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCanadaConditionalMNL(ChoiceModel):\n",
    "    \"\"\"Conditional MNL following for ModeCanada.\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    n_item_features : int\n",
    "        Number of items features\n",
    "    n_session_item_features : int\n",
    "        Number of sessions items features\n",
    "    optimizer : str\n",
    "        tf.keras.optimizer to use for training, default is Adam\n",
    "    lr: float\n",
    "        learning rate for optimizer, default is 1e-3\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Model coefficients instantiation.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Create model weights. Basically is one weight by feature + one for intercept\n",
    "        beta_inter = tf.Variable(tf.random_normal_initializer(0.0, 0.02, seed=42)(shape=(1, 3)),\n",
    "                                 name=\"beta_inter\")\n",
    "        beta_freq_cost_ovt = tf.Variable(tf.random_normal_initializer(0.0, 0.02, seed=42)(shape=(1, 3)),\n",
    "                             name=\"beta_freq_cost_ovt\")\n",
    "        beta_income = tf.Variable(tf.random_normal_initializer(0.0, 0.02, seed=42)(shape=(1, 3)),\n",
    "                             name=\"beta_income\")\n",
    "        beta_ivt = tf.Variable(tf.random_normal_initializer(0.0, 0.02, seed=42)(shape=(1, 4)),\n",
    "                               name=\"beta_ivt\")\n",
    "\n",
    "        # Do not forget to add them to the list of weights, it is mandatory !\n",
    "        self.weights = [beta_inter, beta_freq_cost_ovt, beta_income, beta_ivt]\n",
    "\n",
    "\n",
    "    def compute_utility(self, items_batch, sessions_batch, sessions_items_batch, availabilities_batch, choices_batch):\n",
    "        \"\"\"Method that defines how the model computes the utility of a product.\n",
    "\n",
    "        MNL, here U =\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        items_batch : tuple of np.ndarray (items_features)\n",
    "            Fixed-Item-Features: formatting from ChoiceDataset: a matrix representing the products constant features.\n",
    "            Shape must be (n_items, n_items_features)\n",
    "        sessions_batch : tuple of np.ndarray (sessions_features)\n",
    "            Time-Features. Not used as not conditional MNL, means it is the same for all products and is not implicated in utility computation.\n",
    "            Shape must be (n_sessions, n_sessions_features)\n",
    "        sessions_items_batch : tuple of np.ndarray (sessions_items_features)\n",
    "            Time-Item-Features\n",
    "            Shape must be (n_sessions, n_sessions_items_features)\n",
    "        availabilities_batch : np.ndarray\n",
    "            Availabilities (sessions_items_availabilities)\n",
    "            Shape must be (n_sessions, n_items)\n",
    "        choices_batch : np.ndarray\n",
    "            Choices\n",
    "            Shape must be (n_sessions, )\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Utility of each product for each session.\n",
    "            Shape must be (n_sessions, n_items)\n",
    "        \"\"\"\n",
    "        # We use the fact that items_features is OneHot of the item, letting us selecting the right beta when needed (through dot)\n",
    "        # Utility from items features + intercept\n",
    "\n",
    "        # Concatenation to reach right shape for dot product\n",
    "        full_beta_inter = tf.concat([tf.constant([[.0]]), self.weights[0]], axis=-1)\n",
    "        u_intercept = tf.tensordot(tf.concat([*items_batch], axis=-1),\n",
    "                                   tf.transpose(full_beta_inter), axes=1) # has shape (n_items, )\n",
    "\n",
    "        sessions_items_ivt = sessions_items_batch[0][:, :, 3]\n",
    "        sessions_items_cost_freq_ovt = sessions_items_batch[0][:, :, :3]\n",
    "        u_cost_freq_ovt = tf.squeeze(tf.tensordot(sessions_items_cost_freq_ovt,\n",
    "                                                  tf.transpose(self.weights[1]), axes=1))\n",
    "        u_ivt = tf.multiply(sessions_items_ivt, self.weights[3])\n",
    "\n",
    "        # Concatenation to reach right shape for dot product\n",
    "        full_beta_income = tf.concat([tf.constant([[.0]]), self.weights[2]], axis=-1)\n",
    "        u_income = tf.tensordot(sessions_batch[0], full_beta_income, axes=1)\n",
    "\n",
    "        # Reshaping the intercept that is constant over all sessions (n_items, ) -> (n_sessions, n_items)\n",
    "        u_intercept = tf.concat([tf.transpose(u_intercept)] * (u_income.shape[0]), axis=0)\n",
    "\n",
    "        return u_intercept + u_cost_freq_ovt + u_income + u_ivt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCanadaConditionalMNL(optimizer=\"lbfgs\")\n",
    "history = model.fit(dataset, n_epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition of the utility operations\n",
    "\n",
    "#### > *Intercept*\n",
    "\n",
    "- $U_{inter}(air, s) = \\beta^{inter}_{air} = 0$\n",
    "- $U_{inter}(bus, s) = \\beta^{inter}_{bus}$\n",
    "- $U_{inter}(car, s) = \\beta^{inter}_{car}$\n",
    "- $U_{inter}(train, s) = \\beta^{inter}_{train}$\n",
    "\n",
    "$\\beta^{inter} = \\left(\\begin{array}{c} \n",
    "0 \\\\\n",
    "\\beta^{inter}_{bus} \\\\\n",
    "\\beta^{inter}_{car} \\\\\n",
    "\\beta^{inter}_{train} \\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "$U_{inter} = \\beta^{inter.T}$\n",
    "\n",
    "#### > *Price, Freq, Ovt*\n",
    "- $U_{price, freq, ovt}(air, s) = \\beta^{price} \\cdot price(air, s) + \\beta^{freq} \\cdot freq(air, s) + \\beta^{ovt} \\cdot ovt(air, s)$\n",
    "- $U_{price, freq, ovt}(bus, s) = \\beta^{price} \\cdot price(bus, s) + \\beta^{freq} \\cdot freq(bus, s) + \\beta^{ovt} \\cdot ovt(bus, s)$\n",
    "- $U_{price, freq, ovt}(car, s) = \\beta^{price} \\cdot price(car, s) + \\beta^{freq} \\cdot freq(car, s) + \\beta^{ovt} \\cdot ovt(car, s)$\n",
    "- $U_{price, freq, ovt}(train, s) = \\beta^{price} \\cdot price(train, s) + \\beta^{freq} \\cdot freq(train, s) + \\beta^{ovt} \\cdot ovt(train, s)$\n",
    "\n",
    "$\\beta^{price, freq, ovt} = \\left(\\begin{array}{c} \n",
    "\\beta^{price} \\\\\n",
    "\\beta^{freq} \\\\\n",
    "\\beta^{ovt} \\\\\n",
    "\\end{array}\\right)$ and $sessions\\_items\\_feature[0, :3] = \\left(\\begin{array}{ccc} \n",
    "price(air, 0) & freq(air, 0) & ovt(air, 0) \\\\\n",
    "price(bus, 0) & freq(bus, 0) & ovt(bus, 0) \\\\\n",
    "price(car, 0) & freq(car, 0) & ovt(car, 0) \\\\\n",
    "price(train, 0) & freq(train, 0) & ovt(train, 0) \\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "$U_{price, freq, ovt} = \\beta^{price, freq, ovt .T} \\cdot sessions\\_items\\_feature[:, :3]$\n",
    "\n",
    "Note that in the matrix we couldn't illustrate the sessions dimension, explaining the [0, :3] -> [:, :3].\n",
    "sessions_items_features[:, :3] has a shape of (batch_size, 4, 3) and $ \\beta^{price, freq, ovt}$ a shape of (1, 3).\n",
    "Resulting $U_{price, freq, ovt} $ has thus shape of (batch_size, 4)\n",
    "\n",
    "#### > *Ivt*\n",
    "- $U_{ivt}(air, s) = \\beta^{ivt}_{air} \\cdot ivt(air, s)$\n",
    "- $U_{ivt}(bus, s) = \\beta^{ivt}_{bus} \\cdot ivt(bus, s)$\n",
    "- $U_{ivt}(car, s) = \\beta^{ivt}_{car} \\cdot ivt(car, s)$\n",
    "- $U_{ivt}(train, s) = \\beta^{ivt}_{train} \\cdot ivt(train, s)$\n",
    "\n",
    "$\\beta^{ivt} = \\left(\\begin{array}{c} \n",
    "\\beta^{ivt}_{air} \\\\\n",
    "\\beta^{ivt}_{bus} \\\\\n",
    "\\beta^{ivt}_{car}\\\\\n",
    "\\beta^{ivt}_{train} \\\\\n",
    "\\end{array}\\right)$ and $sessions\\_items\\_features[:, 3] = \\left(\\begin{array}{cccc} \n",
    "ivt(0, air) & ivt(0, bus) & ivt(0, car) & ivt(0,train) \\\\\n",
    "ivt(1, air) & ivt(1, bus) & ivt(1, car) & ivt(1,train) \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "ivt(batch_size, air) & ivt(batch_size, bus) & ivt(batch_size, car) & ivt(batch_size,train) \\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "\n",
    "$U_{ivt} = \\beta^{ivt} * sessions\\_items\\_features[:, 3]$ of shape (batch_size, 4)\n",
    "\n",
    "#### > *Income*\n",
    "- $U_{income}(air, s) = \\beta^{income}_{air} \\cdot income(s)$\n",
    "- $U_{income}(bus, s) = \\beta^{income}_{bus} \\cdot income(s)$\n",
    "- $U_{income}(car, s) = \\beta^{income}_{car} \\cdot income(s)$\n",
    "- $U_{income}(train, s) = \\beta^{income}_{train} \\cdot income(s)$\n",
    "\n",
    "$\\beta^{income} = \\left(\\begin{array}{c} \n",
    "\\beta^{income}_{air} \\\\\n",
    "\\beta^{income}_{bus} \\\\\n",
    "\\beta^{income}_{car}\\\\\n",
    "\\beta^{income}_{train} \\\\\n",
    "\\end{array}\\right)$ and $sessions\\_features = \\left(\\begin{array}{c} \n",
    "income(0) \\\\\n",
    "income(1) \\\\\n",
    "... \\\\\n",
    "income(batch\\_size)) \\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "$U_{income} = \\beta^{income .T} \\cdot sessions\\_features$\n",
    "\n",
    "By concatenating batch_size times $U_{inter}$ over the sessions we obtain 4 matrixes of shape (batch_size, 4).\n",
    "\n",
    "The final utility is then:\n",
    "$U = U_{inter} + U_{price, freq, ovt} + U_{ivt} + U_{income}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We can now test that we oÂ£btain the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.weights[0])\n",
    "print(model.weights[1])\n",
    "print(model.weights[2])\n",
    "print(model.weights[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are organized differently but reach the same values. It is also the case for negative log-lilkelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Neg LikeliHood;\", model.evaluate(dataset) * len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have used a simple linear function for utility computation. We could use any function we would like. Particularly we can use neural networks and activation functions to add non-linearities.\n",
    "\n",
    "A simple example would be:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class NeuralNetUtility(ChoiceModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # First non-linear layer\n",
    "        self.dense_1 = Dense(units=10, activation=\"elu\")\n",
    "        # Second linear layer\n",
    "        self.dense_2 = Dense(units=1, activation=\"linear\")\n",
    "        # We do not forget to specify self.weights with all coefficients that need to be estimated. Easy with TensorFlow.Layer\n",
    "        self.weights = self.dense_1.trainable_variables + self.dense_2.trainable_variables\n",
    "        \n",
    "    def compute_utility(self, items_batch, sessions_batch, sessions_items_batch, availabilities_batch, choices_batch):\n",
    "        # We apply the neural network to all sessions_items_features for all the items\n",
    "        # We then concatenate the utilities of each item of shape (n_sessions, 1) into a single one of shape (n_sessions, n_items)\n",
    "        u = tf.concat([self.dense_2(self.dense_1(sessions_items_batch[0][:, i])) for i in range(sessions_items_batch[0].shape[1])], axis=1)\n",
    "        return u\n",
    "````\n",
    "\n",
    "If you want more complex examples, you can look at the following implementations:\n",
    "- [RUMnet](../choice_learn/models/rumnet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
